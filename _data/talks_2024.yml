meetings:
  - date: "2024.02.15"
    start: "15:00"
    end: "16:20"
    is_upcoming: "False"
    details:
    - time: "15:05"
      title: "Computational models of learning to understand and improve change mechanisms in psychotherapy"
      speaker: "Dr. Isabel Berwian"
      affiliation: "Princeton University"
      abstract: "Psychotherapy aims to achieve change through learning. Early advances in psychotherapy, such as the development of exposure therapy, built on theoretical and experimental evidence from Pavlovian and instrumental conditioning. Now might be the right time to harness newer computational theories of learning such as reinforcement and structure learning and Bayesian inference to improve our understanding of mechanisms of change in psychotherapy and develop individual predictors of treatment response. I will start with introducing a computational perspective on change mechanisms in psychotherapy. Focusing on spontaneous recovery of fear after extinction as an example, I will illustrate how we can use computational modeling of such behavior to gain mechanistic insight and use this to simulate treatment effects and design clinical trials."
    - time: "15:45"
      title: "Preventing depressive relapse – what works for whom"
      speaker: "Dr. Josefien Breedvelt"
      affiliation: "King’s College London"
      abstract: "Individual participant data meta-analyses (IPDMA) have in recent years been applied to a range of mental health conditions to understand individual differences in treatment response and aid the personalisation of interventions. This presentation covers the results of a large-scale effort to collect and synthesise available data from randomised controlled trials studying the efficacy of psychological interventions versus control to prevent depressive relapse for people in remission from depression (see also: itfra.org). In this talk, I will further describe how individual participant data could be used to potentially improve risk stratification using decision tree analyses. Finally, I will reflect on the practical and methodological considerations of using IPDMA to aid the personalisation of interventions to individuals."
  - date: "2024.01.18"
    start: "15:00"
    end: "16:20"
    details:
    - time: "15:05"
      title: "Language and mental health: measures of emotion dynamics from text as linguistic biosocial markers"
      speaker: "Daniela Teodorescu"
      affiliation: "LMU Munich"
      abstract: "Research in psychopathology has shown that, at an aggregate level, the patterns of emotional change over time—emotion dynamics—are indicators of one’s mental health. One’s patterns of emotion change have traditionally been determined through self-reports of emotions; however, there are known issues with accuracy, bias, and convenience. Recent approaches to determining emotion dynamics from one’s everyday utterances, addresses many of these concerns, but it is not yet known whether these measures of utterance emotion dynamics (UED) correlate with mental health diagnoses. Here, for the first time, we study the relationship between tweet emotion dynamics and mental health disorders. We find that each of the UED metrics studied varied by the user’s self-disclosed diagnosis. This work provides important early evidence for how linguistic cues pertaining to emotion dynamics can play a crucial role as biosocial markers for mental illnesses and aid in the understanding, diagnosis, and management of mental health disorders."
    - time: "15:45"
      title: "MentaLLaMA: Interpretable mental health analysis on social media with large language models"
      speaker: "Kailai Yang"
      affiliation: "University of Manchester"
      abstract: "As an integral part of people’s daily lives, social media is becoming a rich source for automatic mental health analysis. As traditional discriminative methods bear poor generalization ability and low interpretability, the recent large language models (LLMs) have been explored for interpretable mental health analysis on social media, which aims to provide detailed explanations along with predictions in zero-shot or few-shot settings. The results show that LLMs still achieve unsatisfactory classification performance in a zero-shot/few-shot manner, which further significantly affects the quality of the generated explanations. Domain-specific finetuning is an effective solution, but faces two critical challenges: 1) lack of high-quality training data. 2) no open-source foundation LLMs. To alleviate these problems, we formally model interpretable mental health analysis as a text generation task, and build the first multi-task and multi-source interpretable mental health instruction (IMHI) dataset with 105K data samples to support LLM instruction tuning and evaluation. The raw social media data are collected from 10 existing sources covering 8 mental health analysis tasks. We prompt ChatGPT with expert-designed few-shot prompts to obtain explanations. To ensure the reliability of the explanations, we perform strict automatic and human evaluations on the correctness, consistency, and quality of generated data. Based on the IMHI dataset and LLaMA2 foundation models, we train MentaLLaMA, the first open-source instruction-following LLM series for interpretable mental health analysis on social media. We evaluate MentaLLaMA and other advanced methods on the IMHI benchmark, the first holistic evaluation benchmark for interpretable mental health analysis. The results show that MentaLLaMA approaches state-of-the-art discriminative methods in correctness and generates human-level explanations. MentaLLaMA models also show strong generalizability to unseen tasks."